{
  "MSE": 0.0001111100608286506,
  "MAE": 0.00803935631189961,
  "Max_Error": 0.08421896398067474,
  "Relative_Error": 16689.757104474545,
  "config": {
    "num_train": 1000,
    "num_test": 1000,
    "num_sensors": 100,
    "train_sample_num": 10,
    "test_sample_num": 100,
    "branch_input_size": 100,
    "trunk_input_size": 1,
    "output_size": 1,
    "num_qubits": 5,
    "net_size": [
      20,
      2,
      10,
      2
    ],
    "scale_coeff": 0.01,
    "learning_rate": 0.0001,
    "num_epochs": 1000,
    "target_error": 0.0001,
    "model_type": "QuanONet",
    "if_trainable_freq": true,
    "batch_size": 100,
    "validation_split": 0
  },
  "training_history": [
    {
      "epoch": 0,
      "train_loss": 0.1552764666825533
    },
    {
      "epoch": 10,
      "train_loss": 0.032894996497780084
    },
    {
      "epoch": 20,
      "train_loss": 0.01088822836522013
    },
    {
      "epoch": 30,
      "train_loss": 0.00999669665005058
    },
    {
      "epoch": 40,
      "train_loss": 0.009308122294023634
    },
    {
      "epoch": 50,
      "train_loss": 0.008486460209824145
    },
    {
      "epoch": 60,
      "train_loss": 0.0072662981553003195
    },
    {
      "epoch": 70,
      "train_loss": 0.005192342619411647
    },
    {
      "epoch": 80,
      "train_loss": 0.0034164251084439455
    },
    {
      "epoch": 90,
      "train_loss": 0.0027764889434911313
    },
    {
      "epoch": 100,
      "train_loss": 0.0024590156564954667
    },
    {
      "epoch": 110,
      "train_loss": 0.002320224565919489
    },
    {
      "epoch": 120,
      "train_loss": 0.0021881824324373154
    },
    {
      "epoch": 130,
      "train_loss": 0.0020886999496724456
    },
    {
      "epoch": 140,
      "train_loss": 0.00194825331796892
    },
    {
      "epoch": 150,
      "train_loss": 0.0018577857466880233
    },
    {
      "epoch": 160,
      "train_loss": 0.0016880690667312591
    },
    {
      "epoch": 170,
      "train_loss": 0.0015295011654961855
    },
    {
      "epoch": 180,
      "train_loss": 0.0013618109904928134
    },
    {
      "epoch": 190,
      "train_loss": 0.0011825487419264392
    },
    {
      "epoch": 200,
      "train_loss": 0.0010202304820995777
    },
    {
      "epoch": 210,
      "train_loss": 0.0008792550157522783
    },
    {
      "epoch": 220,
      "train_loss": 0.0008051018472178839
    },
    {
      "epoch": 230,
      "train_loss": 0.0007214189731166699
    },
    {
      "epoch": 240,
      "train_loss": 0.0006953521043760702
    },
    {
      "epoch": 250,
      "train_loss": 0.0006507111835526302
    },
    {
      "epoch": 260,
      "train_loss": 0.0006336968287359923
    },
    {
      "epoch": 270,
      "train_loss": 0.0006156433772412129
    },
    {
      "epoch": 280,
      "train_loss": 0.0005898790477658622
    },
    {
      "epoch": 290,
      "train_loss": 0.0005751379462890327
    },
    {
      "epoch": 300,
      "train_loss": 0.0005498637276468799
    },
    {
      "epoch": 310,
      "train_loss": 0.0005586498160846531
    },
    {
      "epoch": 320,
      "train_loss": 0.0005271535261999815
    },
    {
      "epoch": 330,
      "train_loss": 0.0005061206995742396
    },
    {
      "epoch": 340,
      "train_loss": 0.0004902435673284345
    },
    {
      "epoch": 350,
      "train_loss": 0.0004779979898012243
    },
    {
      "epoch": 360,
      "train_loss": 0.0004552765574771911
    },
    {
      "epoch": 370,
      "train_loss": 0.00044137141783721743
    },
    {
      "epoch": 380,
      "train_loss": 0.0004134725988842547
    },
    {
      "epoch": 390,
      "train_loss": 0.0003900743887061253
    },
    {
      "epoch": 400,
      "train_loss": 0.00037765080778626723
    },
    {
      "epoch": 410,
      "train_loss": 0.00035846261758706535
    },
    {
      "epoch": 420,
      "train_loss": 0.0003367213315505069
    },
    {
      "epoch": 430,
      "train_loss": 0.00031905609677778556
    },
    {
      "epoch": 440,
      "train_loss": 0.00029287832279806025
    },
    {
      "epoch": 450,
      "train_loss": 0.0002768579604162369
    },
    {
      "epoch": 460,
      "train_loss": 0.000258831860992359
    },
    {
      "epoch": 470,
      "train_loss": 0.00023339944847975859
    },
    {
      "epoch": 480,
      "train_loss": 0.00021765992270957212
    },
    {
      "epoch": 490,
      "train_loss": 0.00020367615812574513
    },
    {
      "epoch": 500,
      "train_loss": 0.00019667438726173714
    },
    {
      "epoch": 510,
      "train_loss": 0.00017769729347492103
    },
    {
      "epoch": 520,
      "train_loss": 0.00017394504189724102
    },
    {
      "epoch": 530,
      "train_loss": 0.0001723803325876361
    },
    {
      "epoch": 540,
      "train_loss": 0.00015850484458496795
    },
    {
      "epoch": 550,
      "train_loss": 0.0001557552587473765
    },
    {
      "epoch": 560,
      "train_loss": 0.00015436832021805457
    },
    {
      "epoch": 570,
      "train_loss": 0.00014792212474276311
    },
    {
      "epoch": 580,
      "train_loss": 0.00014507265703286976
    },
    {
      "epoch": 590,
      "train_loss": 0.00014776047100895084
    },
    {
      "epoch": 600,
      "train_loss": 0.0001475054590991931
    },
    {
      "epoch": 610,
      "train_loss": 0.0001418120502785314
    },
    {
      "epoch": 620,
      "train_loss": 0.0001386651348002488
    },
    {
      "epoch": 630,
      "train_loss": 0.00014040858615771868
    },
    {
      "epoch": 640,
      "train_loss": 0.00013764249146333896
    },
    {
      "epoch": 650,
      "train_loss": 0.00014273524619056843
    },
    {
      "epoch": 660,
      "train_loss": 0.00013602491191704757
    },
    {
      "epoch": 670,
      "train_loss": 0.00013421654963167385
    },
    {
      "epoch": 680,
      "train_loss": 0.00013594949719845318
    },
    {
      "epoch": 690,
      "train_loss": 0.0001319815306487726
    },
    {
      "epoch": 700,
      "train_loss": 0.00013025492233282421
    },
    {
      "epoch": 710,
      "train_loss": 0.00013114345943904482
    },
    {
      "epoch": 720,
      "train_loss": 0.0001322969372267835
    },
    {
      "epoch": 730,
      "train_loss": 0.00013272594682348427
    },
    {
      "epoch": 740,
      "train_loss": 0.0001275848496152321
    },
    {
      "epoch": 750,
      "train_loss": 0.00012341120418568607
    },
    {
      "epoch": 760,
      "train_loss": 0.00012426770314050373
    },
    {
      "epoch": 770,
      "train_loss": 0.00012544560187961905
    },
    {
      "epoch": 780,
      "train_loss": 0.00012836818394134752
    },
    {
      "epoch": 790,
      "train_loss": 0.000126233674454852
    },
    {
      "epoch": 800,
      "train_loss": 0.00012294048108742571
    },
    {
      "epoch": 810,
      "train_loss": 0.00012036201937007718
    },
    {
      "epoch": 820,
      "train_loss": 0.00012197716110676992
    },
    {
      "epoch": 830,
      "train_loss": 0.0001196684467868181
    },
    {
      "epoch": 840,
      "train_loss": 0.00011830705945612862
    },
    {
      "epoch": 850,
      "train_loss": 0.00011737654844182544
    },
    {
      "epoch": 860,
      "train_loss": 0.00011835870944196358
    },
    {
      "epoch": 870,
      "train_loss": 0.00012108621456718538
    },
    {
      "epoch": 880,
      "train_loss": 0.00011851156203192659
    },
    {
      "epoch": 890,
      "train_loss": 0.00011212214347324334
    },
    {
      "epoch": 900,
      "train_loss": 0.00011740205147361848
    },
    {
      "epoch": 910,
      "train_loss": 0.00011489994321891572
    },
    {
      "epoch": 920,
      "train_loss": 0.0001126061753166141
    },
    {
      "epoch": 930,
      "train_loss": 0.00011559513986867387
    },
    {
      "epoch": 940,
      "train_loss": 0.00011794405720138456
    },
    {
      "epoch": 950,
      "train_loss": 0.00011424831071053631
    },
    {
      "epoch": 960,
      "train_loss": 0.00011228804760321509
    },
    {
      "epoch": 970,
      "train_loss": 0.00011040798955946229
    },
    {
      "epoch": 980,
      "train_loss": 0.00011380737676518038
    },
    {
      "epoch": 990,
      "train_loss": 0.00011342799945850856
    }
  ]
}