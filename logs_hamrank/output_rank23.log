[WARNING] ME(2269528,7f375b9a4740,python):2025-10-06-02:31:15.065.388 [mindspore/ccsrc/runtime/hardware/device_context_manager.cc:601] SelectGpuPlugin] Env CUDA_HOME is /usr/local/cuda, but can not find suitable gpu plugin.
=== ODE Operator QuanONet Training System ===
Operator type: Homogeneous
Loaded configuration from configs/config_ODE.json
Logs directory: hamrank_quanonet/logs
Checkpoints directory: hamrank_quanonet/checkpoints
Data directory: hamrank_quanonet/data
Command line argument overrides random seed setting
Setting random seed: 1
Using configuration: {'// Universal ODE operator configuration file': 'config_ODE.json', '// Supported operator types': ['Inverse', 'Homogeneous', 'Nonlinear', 'Custom'], '// Data generation parameters': '', 'num_train': 1000, 'num_test': 1000, 'num_points': 100, 'train_sample_num': 10, 'test_sample_num': 100, 'length_scale': 0.2, 'num_cal': 1000, '// Model parameters': '', 'branch_input_size': 100, 'trunk_input_size': 1, 'output_size': 1, 'num_qubits': 5, 'net_size': [20, 2, 10, 2], 'scale_coeff': 0.01, 'model_type': 'QuanONet', 'if_trainable_freq': True, '// Training parameters': '', 'learning_rate': 0.0001, 'num_epochs': 1000, 'target_error': 0.0001, 'batch_size': 100, 'validation_split': 0, 'patience': 20, '// Operator-specific parameters': '', 'custom_name': None, 'custom_ode_description': 'Only used when operator_type=Custom, specify via command line --custom_ode', 'operator_type': 'Homogeneous', 'random_seed': 1, 'if_save': True, 'ham_rank': 23, 'if_train': True}
=== QuanONet Homogeneous Operator Solving Pipeline ===
Operator Description: Homogeneous operator (du/dx = u + u0(x))
Start Time: 2025-10-06 02:31:28.474097

=== Homogeneous Operator Data Preparation ===
Generating new data...
Generating Homogeneous operator data...
Loaded 2000 existing samples from main file
Saving data to hamrank_quanonet/data/Homogeneous/rank23/qubits5/Homogeneous_Operator_dataset_5_1000_1000_100_10_100.npz...
Data generation and saving completed!

=== Data Information ===
Operator Type: Homogeneous
Operator Description: Homogeneous operator (du/dx = u + u0(x))
Number of Training Samples: 10000
Number of Test Samples: 100000
Input Dimension: 101
Output Dimension: 1
Branch Input Dimension: 100
Trunk Input Dimension: 1
Warning: validation_split=0 is invalid, not using validation set

=== Model Creation ===
Using Hamiltonian:   (1, 1)	(4.888610889064949+0j)
  (2, 2)	(1.9187711395047335+0j)
  (3, 3)	(-4.999999999999999+0j)
  (4, 4)	(0.33165284973017023+0j)
  (6, 6)	(1.8650092768158366+0j)
  (7, 7)	(-4.817117226558083+0j)
  (10, 10)	(-4.016531661669499+0j)
  (13, 13)	(3.34625671897373+0j)
  (14, 14)	(-3.3016958043543108+0j)
  (16, 16)	(2.481656543798394+0j)
  (17, 17)	(3.763891522960381+0j)
  (18, 18)	(-1.8657582184075712+0j)
  (19, 19)	(-4.609452167671177+0j)
  (20, 20)	(-0.7889237499494781+0j)
  (21, 21)	(3.9460666350384743+0j)
  (22, 22)	(4.682615757193975+0j)
  (23, 23)	(1.92322615669314+0j)
  (24, 24)	(3.7814250342941307+0j)
  (25, 25)	(-1.8448436899393705+0j)
  (26, 26)	(4.5788953015050184+0j)
  (27, 27)	(5+0j)
  (28, 28)	(-4.1495578863022216+0j)
  (29, 29)	(2.501443149449675+0j)
Model Type: QuanONet
Circuit Parameters: 
                                Circuit Summary                                 
╭────────────────────────┬─────────────────────────────────────────────────────╮
│ Info                   │ value                                               │
├────────────────────────┼─────────────────────────────────────────────────────┤
│ Number of qubit        │ 5                                                   │
├────────────────────────┼─────────────────────────────────────────────────────┤
│ Total number of gate   │ 1350                                                │
│ Barrier                │ 0                                                   │
│ Noise Channel          │ 0                                                   │
│ Measurement            │ 0                                                   │
├────────────────────────┼─────────────────────────────────────────────────────┤
│ Parameter gate         │ 1050                                                │
│ 150 encoder parameters │ xi_l0_q0, xi_l0_q1, xi_l0_q2, xi_l0_q3, xi_l0_q4,   │
│                        │ xi_l1_q0, xi_l1_q1, xi_l1_q2, xi_l1_q3, xi_l1_q4... │
│ 900 ansatz parameters  │ para0, para1, para2, para3, para4, para5, para6,    │
│                        │ para7, para8, para9...                              │
╰────────────────────────┴─────────────────────────────────────────────────────╯
Trainable Frequency: Enabled
Network Structure: [20, 2, 10, 2]
Total Parameters: 1,200

=== Model Training ===
Training Parameters:
  Learning Rate: 0.0001
  Max Epochs: 1000
  Target Error: 0.0001
  Batch Size: 100
  Training Batches: 100
  Use Validation Set: No
  Checkpoint Interval: 50 epochs

Starting training...
Training Progress:   0%|          | 0/1000 [00:00<?, ?it/s]  Found better model: Training loss improved from inf to 0.505407
Epoch 0: Train=0.505407, Best Train=0.505407
Training Progress:   0%|          | 1/1000 [01:45<29:18:09, 105.60s/it]Training Progress:   0%|          | 2/1000 [03:25<28:18:44, 102.13s/it]Training Progress:   0%|          | 3/1000 [05:15<29:14:32, 105.59s/it]Training Progress:   0%|          | 4/1000 [07:03<29:31:49, 106.74s/it]Training Progress:   0%|          | 5/1000 [08:57<30:12:19, 109.29s/it]Training Progress:   1%|          | 6/1000 [10:47<30:17:20, 109.70s/it]Training Progress:   1%|          | 7/1000 [12:40<30:29:04, 110.52s/it]Training Progress:   1%|          | 8/1000 [14:30<30:26:32, 110.48s/it]Training Progress:   1%|          | 9/1000 [16:18<30:14:00, 109.83s/it]Training Progress:   1%|          | 10/1000 [18:07<30:08:30, 109.61s/it]  Found better model: Training loss improved from 0.505407 to 0.111415
Training Progress:   1%|          | 11/1000 [19:56<29:59:31, 109.17s/it]Training Progress:   1%|          | 12/1000 [21:44<29:51:51, 108.82s/it]Training Progress:   1%|▏         | 13/1000 [23:39<30:24:20, 110.90s/it]Training Progress:   1%|▏         | 14/1000 [25:25<29:56:44, 109.33s/it]Training Progress:   2%|▏         | 15/1000 [27:16<30:04:36, 109.93s/it]Training Progress:   2%|▏         | 16/1000 [29:06<29:59:38, 109.73s/it]Training Progress:   2%|▏         | 17/1000 [31:01<30:25:43, 111.44s/it]Training Progress:   2%|▏         | 18/1000 [32:40<29:24:44, 107.83s/it]Training Progress:   2%|▏         | 19/1000 [34:33<29:47:47, 109.34s/it]Training Progress:   2%|▏         | 20/1000 [36:23<29:45:17, 109.30s/it]  Found better model: Training loss improved from 0.111415 to 0.022093
Training Progress:   2%|▏         | 21/1000 [38:15<29:59:32, 110.29s/it]Training Progress:   2%|▏         | 22/1000 [40:07<30:07:03, 110.86s/it]Training Progress:   2%|▏         | 23/1000 [41:59<30:10:49, 111.21s/it]Training Progress:   2%|▏         | 24/1000 [43:54<30:26:01, 112.26s/it]Training Progress:   2%|▎         | 25/1000 [45:47<30:26:21, 112.39s/it]Training Progress:   3%|▎         | 26/1000 [47:33<29:52:18, 110.41s/it]Training Progress:   3%|▎         | 27/1000 [49:17<29:19:17, 108.49s/it]Training Progress:   3%|▎         | 28/1000 [51:09<29:38:26, 109.78s/it]Training Progress:   3%|▎         | 29/1000 [52:55<29:18:14, 108.65s/it]Training Progress:   3%|▎         | 30/1000 [54:53<29:58:55, 111.27s/it]  Found better model: Training loss improved from 0.022093 to 0.011866
Training Progress:   3%|▎         | 31/1000 [56:40<29:39:44, 110.20s/it]Training Progress:   3%|▎         | 32/1000 [58:32<29:44:38, 110.62s/it]Training Progress:   3%|▎         | 33/1000 [1:00:24<29:48:05, 110.95s/it]Training Progress:   3%|▎         | 34/1000 [1:02:13<29:38:15, 110.45s/it]Training Progress:   4%|▎         | 35/1000 [1:04:05<29:41:58, 110.80s/it]Training Progress:   4%|▎         | 36/1000 [1:05:53<29:29:30, 110.13s/it]Training Progress:   4%|▎         | 37/1000 [1:07:41<29:15:28, 109.38s/it]Training Progress:   4%|▍         | 38/1000 [1:09:34<29:32:04, 110.52s/it]Training Progress:   4%|▍         | 39/1000 [1:11:25<29:34:23, 110.78s/it]Training Progress:   4%|▍         | 40/1000 [1:13:21<29:55:42, 112.23s/it]  Found better model: Training loss improved from 0.011866 to 0.010058
Training Progress:   4%|▍         | 41/1000 [1:15:12<29:50:16, 112.01s/it]Training Progress:   4%|▍         | 42/1000 [1:17:01<29:32:36, 111.02s/it]Training Progress:   4%|▍         | 43/1000 [1:18:58<29:58:25, 112.75s/it]Training Progress:   4%|▍         | 44/1000 [1:20:49<29:49:03, 112.28s/it]Training Progress:   4%|▍         | 45/1000 [1:22:48<30:16:24, 114.12s/it]Training Progress:   5%|▍         | 46/1000 [1:24:41<30:13:02, 114.03s/it]Training Progress:   5%|▍         | 47/1000 [1:26:32<29:54:48, 113.00s/it]Training Progress:   5%|▍         | 48/1000 [1:28:22<29:39:37, 112.16s/it]Training Progress:   5%|▍         | 49/1000 [1:30:15<29:41:43, 112.41s/it]Training Progress:   5%|▌         | 50/1000 [1:32:05<29:28:23, 111.69s/it]  Found better model: Training loss improved from 0.010058 to 0.008648
Training Progress:   5%|▌         | 51/1000 [1:33:56<29:22:15, 111.42s/it]Training Progress:   5%|▌         | 52/1000 [1:35:41<28:49:02, 109.43s/it]Training Progress:   5%|▌         | 53/1000 [1:37:34<29:04:40, 110.54s/it]Training Progress:   5%|▌         | 54/1000 [1:39:30<29:27:38, 112.11s/it]Training Progress:   6%|▌         | 55/1000 [1:41:21<29:21:26, 111.84s/it]Training Progress:   6%|▌         | 56/1000 [1:43:13<29:21:44, 111.97s/it]Training Progress:   6%|▌         | 57/1000 [1:45:04<29:12:58, 111.54s/it]Training Progress:   6%|▌         | 58/1000 [1:46:49<28:40:20, 109.58s/it]Training Progress:   6%|▌         | 59/1000 [1:48:41<28:48:59, 110.24s/it]Training Progress:   6%|▌         | 60/1000 [1:50:32<28:53:56, 110.68s/it]  Found better model: Training loss improved from 0.008648 to 0.006883
Training Progress:   6%|▌         | 61/1000 [1:52:19<28:35:44, 109.63s/it]Training Progress:   6%|▌         | 62/1000 [1:54:17<29:11:20, 112.03s/it]Training Progress:   6%|▋         | 63/1000 [1:56:09<29:09:19, 112.02s/it]Training Progress:   6%|▋         | 64/1000 [1:57:59<28:59:27, 111.50s/it]Training Progress:   6%|▋         | 65/1000 [1:59:56<29:24:10, 113.21s/it]Training Progress:   7%|▋         | 66/1000 [2:01:54<29:43:16, 114.56s/it]Training Progress:   7%|▋         | 67/1000 [2:03:43<29:13:37, 112.77s/it]Training Progress:   7%|▋         | 68/1000 [2:05:35<29:09:59, 112.66s/it]Training Progress:   7%|▋         | 69/1000 [2:07:29<29:14:18, 113.06s/it]Training Progress:   7%|▋         | 70/1000 [2:09:19<28:57:19, 112.09s/it]  Found better model: Training loss improved from 0.006883 to 0.005037
Training Progress:   7%|▋         | 71/1000 [2:11:12<29:00:33, 112.42s/it]Training Progress:   7%|▋         | 72/1000 [2:13:05<29:01:26, 112.59s/it]Training Progress:   7%|▋         | 73/1000 [2:15:02<29:17:38, 113.76s/it]Training Progress:   7%|▋         | 74/1000 [2:16:51<28:56:04, 112.49s/it]Training Progress:   8%|▊         | 75/1000 [2:18:43<28:52:52, 112.40s/it]Training Progress:   8%|▊         | 76/1000 [2:20:32<28:31:34, 111.14s/it]Training Progress:   8%|▊         | 77/1000 [2:22:21<28:21:09, 110.58s/it]Training Progress:   8%|▊         | 78/1000 [2:24:16<28:39:12, 111.88s/it]Training Progress:   8%|▊         | 79/1000 [2:26:10<28:47:07, 112.52s/it]Training Progress:   8%|▊         | 80/1000 [2:28:01<28:40:36, 112.21s/it]  Found better model: Training loss improved from 0.005037 to 0.003761
Training Progress:   8%|▊         | 81/1000 [2:29:51<28:28:04, 111.52s/it]Training Progress:   8%|▊         | 82/1000 [2:31:42<28:24:16, 111.39s/it]Training Progress:   8%|▊         | 83/1000 [2:33:32<28:14:12, 110.85s/it]Training Progress:   8%|▊         | 84/1000 [2:35:22<28:07:36, 110.54s/it]Training Progress:   8%|▊         | 85/1000 [2:37:18<28:29:49, 112.12s/it]Training Progress:   9%|▊         | 86/1000 [2:39:06<28:13:13, 111.15s/it]Training Progress:   9%|▊         | 87/1000 [2:40:58<28:14:16, 111.34s/it]Training Progress:   9%|▉         | 88/1000 [2:42:47<28:00:52, 110.58s/it]Training Progress:   9%|▉         | 89/1000 [2:44:41<28:12:46, 111.49s/it]Training Progress:   9%|▉         | 90/1000 [2:46:33<28:13:12, 111.64s/it]  Found better model: Training loss improved from 0.003761 to 0.003292
Training Progress:   9%|▉         | 91/1000 [2:48:27<28:24:19, 112.50s/it]Training Progress:   9%|▉         | 92/1000 [2:50:18<28:16:35, 112.11s/it]Training Progress:   9%|▉         | 93/1000 [2:52:15<28:35:31, 113.49s/it]Training Progress:   9%|▉         | 94/1000 [2:54:03<28:07:01, 111.72s/it]Training Progress:  10%|▉         | 95/1000 [2:56:05<28:52:32, 114.86s/it]Training Progress:  10%|▉         | 96/1000 [2:58:07<29:24:14, 117.10s/it]Training Progress:  10%|▉         | 97/1000 [3:00:02<29:13:42, 116.53s/it]Training Progress:  10%|▉         | 98/1000 [3:02:00<29:17:57, 116.94s/it]Training Progress:  10%|▉         | 99/1000 [3:03:47<28:28:06, 113.75s/it]Training Progress:  10%|█         | 100/1000 [3:05:39<28:22:22, 113.49s/it]  Found better model: Training loss improved from 0.003292 to 0.003114
Epoch 100: Train=0.003114, Best Train=0.003114
Training Progress:  10%|█         | 101/1000 [3:07:37<28:36:42, 114.57s/it]Training Progress:  10%|█         | 102/1000 [3:09:33<28:42:35, 115.10s/it]Training Progress:  10%|█         | 103/1000 [3:11:28<28:42:27, 115.21s/it]Training Progress:  10%|█         | 104/1000 [3:13:15<28:00:34, 112.54s/it]Training Progress:  10%|█         | 105/1000 [3:15:03<27:40:13, 111.30s/it]Training Progress:  11%|█         | 106/1000 [3:16:59<27:57:09, 112.56s/it]Training Progress:  11%|█         | 107/1000 [3:18:52<27:58:33, 112.78s/it]Training Progress:  11%|█         | 108/1000 [3:20:45<27:56:19, 112.76s/it]Training Progress:  11%|█         | 109/1000 [3:22:40<28:05:16, 113.49s/it]Training Progress:  11%|█         | 110/1000 [3:24:26<27:31:52, 111.36s/it]  Found better model: Training loss improved from 0.003114 to 0.002920
Training Progress:  11%|█         | 111/1000 [3:26:22<27:51:59, 112.85s/it]Training Progress:  11%|█         | 112/1000 [3:28:21<28:17:26, 114.69s/it]Training Progress:  11%|█▏        | 113/1000 [3:30:15<28:11:31, 114.42s/it]Training Progress:  11%|█▏        | 114/1000 [3:32:04<27:43:51, 112.68s/it]Training Progress:  12%|█▏        | 115/1000 [3:33:59<27:54:26, 113.52s/it]Training Progress:  12%|█▏        | 116/1000 [3:35:53<27:51:38, 113.46s/it]Training Progress:  12%|█▏        | 117/1000 [3:37:43<27:36:10, 112.54s/it]Training Progress:  12%|█▏        | 118/1000 [3:39:36<27:37:14, 112.74s/it]Training Progress:  12%|█▏        | 119/1000 [3:41:28<27:32:31, 112.54s/it]Training Progress:  12%|█▏        | 120/1000 [3:43:26<27:51:35, 113.97s/it]  Found better model: Training loss improved from 0.002920 to 0.002876
Training Progress:  12%|█▏        | 121/1000 [3:45:11<27:11:34, 111.37s/it]Training Progress:  12%|█▏        | 122/1000 [3:46:59<26:57:33, 110.54s/it]Training Progress:  12%|█▏        | 123/1000 [3:48:47<26:40:12, 109.48s/it]Training Progress:  12%|█▏        | 124/1000 [3:50:34<26:28:25, 108.80s/it]Training Progress:  12%|█▎        | 125/1000 [3:52:25<26:39:19, 109.67s/it]Training Progress:  13%|█▎        | 126/1000 [3:54:16<26:39:50, 109.83s/it]Training Progress:  13%|█▎        | 127/1000 [3:56:11<27:00:08, 111.35s/it]Training Progress:  13%|█▎        | 128/1000 [3:57:59<26:45:52, 110.50s/it]Training Progress:  13%|█▎        | 129/1000 [3:59:48<26:35:44, 109.92s/it]Training Progress:  13%|█▎        | 130/1000 [4:01:38<26:35:05, 110.01s/it]  Found better model: Training loss improved from 0.002876 to 0.002779
Training Progress:  13%|█▎        | 131/1000 [4:03:28<26:32:19, 109.94s/it]Training Progress:  13%|█▎        | 132/1000 [4:05:20<26:39:02, 110.53s/it]Training Progress:  13%|█▎        | 133/1000 [4:07:13<26:51:21, 111.51s/it]Training Progress:  13%|█▎        | 134/1000 [4:08:59<26:23:28, 109.71s/it]Training Progress:  14%|█▎        | 135/1000 [4:10:50<26:29:50, 110.28s/it]Training Progress:  14%|█▎        | 136/1000 [4:12:41<26:28:29, 110.31s/it]Training Progress:  14%|█▎        | 137/1000 [4:14:29<26:16:17, 109.59s/it]Training Progress:  14%|█▍        | 138/1000 [4:16:19<26:16:37, 109.74s/it]Training Progress:  14%|█▍        | 139/1000 [4:18:05<25:59:56, 108.71s/it]Training Progress:  14%|█▍        | 140/1000 [4:19:57<26:13:11, 109.76s/it]  Found better model: Training loss improved from 0.002779 to 0.002653
Training Progress:  14%|█▍        | 141/1000 [4:21:53<26:37:41, 111.60s/it]Training Progress:  14%|█▍        | 142/1000 [4:23:42<26:24:45, 110.82s/it]Training Progress:  14%|█▍        | 143/1000 [4:25:34<26:25:20, 110.99s/it]Training Progress:  14%|█▍        | 144/1000 [4:27:26<26:28:42, 111.36s/it]Training Progress:  14%|█▍        | 145/1000 [4:29:16<26:22:44, 111.07s/it]Training Progress:  15%|█▍        | 146/1000 [4:31:08<26:23:07, 111.23s/it]Training Progress:  15%|█▍        | 147/1000 [4:32:57<26:14:21, 110.74s/it]Training Progress:  15%|█▍        | 148/1000 [4:34:48<26:13:37, 110.82s/it]Training Progress:  15%|█▍        | 149/1000 [4:36:37<26:03:38, 110.25s/it]Training Progress:  15%|█▌        | 150/1000 [4:38:26<25:56:54, 109.90s/it]  Found better model: Training loss improved from 0.002653 to 0.002573
Training Progress:  15%|█▌        | 151/1000 [4:40:21<26:15:02, 111.31s/it]Training Progress:  15%|█▌        | 152/1000 [4:42:17<26:32:35, 112.68s/it]Training Progress:  15%|█▌        | 153/1000 [4:44:09<26:27:23, 112.45s/it]Training Progress:  15%|█▌        | 154/1000 [4:45:59<26:16:52, 111.83s/it]Training Progress:  16%|█▌        | 155/1000 [4:47:50<26:10:14, 111.50s/it]Training Progress:  16%|█▌        | 156/1000 [4:49:43<26:15:33, 112.01s/it]Training Progress:  16%|█▌        | 157/1000 [4:51:37<26:21:40, 112.58s/it]Training Progress:  16%|█▌        | 158/1000 [4:53:25<26:00:05, 111.17s/it]Training Progress:  16%|█▌        | 159/1000 [4:55:19<26:11:50, 112.14s/it]Training Progress:  16%|█▌        | 160/1000 [4:57:09<26:00:10, 111.44s/it]  Found better model: Training loss improved from 0.002573 to 0.002537
Training Progress:  16%|█▌        | 161/1000 [4:59:03<26:09:26, 112.24s/it]Training Progress:  16%|█▌        | 162/1000 [5:00:59<26:21:15, 113.22s/it]Training Progress:  16%|█▋        | 163/1000 [5:02:46<25:55:53, 111.53s/it]Training Progress:  16%|█▋        | 164/1000 [5:04:34<25:37:57, 110.38s/it]Training Progress:  16%|█▋        | 165/1000 [5:06:24<25:32:50, 110.14s/it]Training Progress:  17%|█▋        | 166/1000 [5:08:17<25:46:18, 111.25s/it]Training Progress:  17%|█▋        | 167/1000 [5:10:13<26:02:09, 112.52s/it]Training Progress:  17%|█▋        | 168/1000 [5:11:59<25:34:48, 110.68s/it]Training Progress:  17%|█▋        | 169/1000 [5:13:51<25:37:13, 110.99s/it]Training Progress:  17%|█▋        | 170/1000 [5:15:48<25:59:01, 112.70s/it]  Found better model: Training loss improved from 0.002537 to 0.002444
Training Progress:  17%|█▋        | 171/1000 [5:17:40<25:54:16, 112.49s/it]Training Progress:  17%|█▋        | 172/1000 [5:19:28<25:36:44, 111.36s/it]Training Progress:  17%|█▋        | 173/1000 [5:21:18<25:29:11, 110.94s/it]Training Progress:  17%|█▋        | 174/1000 [5:23:06<25:15:10, 110.06s/it]Training Progress:  18%|█▊        | 175/1000 [5:24:59<25:24:15, 110.86s/it]Training Progress:  18%|█▊        | 176/1000 [5:26:43<24:55:25, 108.89s/it]Training Progress:  18%|█▊        | 177/1000 [5:28:40<25:24:51, 111.17s/it]Training Progress:  18%|█▊        | 178/1000 [5:30:29<25:16:10, 110.67s/it]Training Progress:  18%|█▊        | 179/1000 [5:32:23<25:25:31, 111.49s/it]Training Progress:  18%|█▊        | 180/1000 [5:34:07<24:55:03, 109.39s/it]  Found better model: Training loss improved from 0.002444 to 0.002379
Training Progress:  18%|█▊        | 181/1000 [5:35:59<25:00:35, 109.93s/it]Training Progress:  18%|█▊        | 182/1000 [5:37:54<25:22:44, 111.69s/it]Training Progress:  18%|█▊        | 183/1000 [5:39:43<25:06:41, 110.65s/it]Training Progress:  18%|█▊        | 184/1000 [5:41:35<25:12:23, 111.20s/it]Training Progress:  18%|█▊        | 185/1000 [5:43:22<24:52:30, 109.88s/it]Training Progress:  19%|█▊        | 186/1000 [5:45:11<24:45:57, 109.53s/it]Training Progress:  19%|█▊        | 187/1000 [5:46:57<24:31:20, 108.59s/it]Training Progress:  19%|█▉        | 188/1000 [5:48:49<24:45:27, 109.76s/it]Training Progress:  19%|█▉        | 189/1000 [5:50:42<24:56:42, 110.73s/it]Training Progress:  19%|█▉        | 190/1000 [5:52:34<24:57:36, 110.93s/it]  Found better model: Training loss improved from 0.002379 to 0.002300
Training Progress:  19%|█▉        | 191/1000 [5:54:27<25:02:54, 111.46s/it]Training Progress:  19%|█▉        | 192/1000 [5:56:16<24:51:28, 110.75s/it]Training Progress:  19%|█▉        | 193/1000 [5:58:07<24:51:52, 110.92s/it]Training Progress:  19%|█▉        | 194/1000 [5:59:55<24:39:01, 110.10s/it]Training Progress:  20%|█▉        | 195/1000 [6:01:46<24:42:02, 110.46s/it]Training Progress:  20%|█▉        | 196/1000 [6:03:38<24:43:35, 110.72s/it]Training Progress:  20%|█▉        | 197/1000 [6:05:29<24:43:38, 110.86s/it]Training Progress:  20%|█▉        | 198/1000 [6:07:24<24:59:11, 112.16s/it]Training Progress:  20%|█▉        | 199/1000 [6:09:12<24:41:30, 110.97s/it]Training Progress:  20%|██        | 200/1000 [6:11:10<25:05:22, 112.90s/it]  Found better model: Training loss improved from 0.002300 to 0.002185
Epoch 200: Train=0.002185, Best Train=0.002185
Training Progress:  20%|██        | 201/1000 [6:13:06<25:15:26, 113.80s/it]Training Progress:  20%|██        | 202/1000 [6:15:03<25:28:18, 114.91s/it]Training Progress:  20%|██        | 203/1000 [6:16:54<25:10:22, 113.70s/it]Training Progress:  20%|██        | 204/1000 [6:18:42<24:45:27, 111.97s/it]Training Progress:  20%|██        | 205/1000 [6:20:35<24:47:15, 112.25s/it]Training Progress:  21%|██        | 206/1000 [6:22:24<24:34:04, 111.39s/it]Training Progress:  21%|██        | 207/1000 [6:24:16<24:33:49, 111.51s/it]Training Progress:  21%|██        | 208/1000 [6:26:13<24:53:19, 113.13s/it]Training Progress:  21%|██        | 209/1000 [6:28:04<24:41:48, 112.40s/it]Training Progress:  21%|██        | 210/1000 [6:29:42<23:44:36, 108.20s/it]  Found better model: Training loss improved from 0.002185 to 0.002075
Training Progress:  21%|██        | 211/1000 [6:31:21<23:05:44, 105.38s/it]Training Progress:  21%|██        | 212/1000 [6:33:01<22:43:58, 103.86s/it]Training Progress:  21%|██▏       | 213/1000 [6:34:36<22:05:24, 101.05s/it]Training Progress:  21%|██▏       | 214/1000 [6:36:05<21:16:46, 97.46s/it] Training Progress:  22%|██▏       | 215/1000 [6:37:37<20:55:42, 95.98s/it]Training Progress:  22%|██▏       | 216/1000 [6:39:09<20:38:05, 94.75s/it]Training Progress:  22%|██▏       | 217/1000 [6:40:39<20:18:40, 93.38s/it]Training Progress:  22%|██▏       | 218/1000 [6:42:09<20:03:54, 92.37s/it]Training Progress:  22%|██▏       | 219/1000 [6:43:35<19:37:28, 90.46s/it]Training Progress:  22%|██▏       | 220/1000 [6:45:03<19:25:12, 89.63s/it]  Found better model: Training loss improved from 0.002075 to 0.001974
Training Progress:  22%|██▏       | 221/1000 [6:46:31<19:16:12, 89.05s/it]Training Progress:  22%|██▏       | 222/1000 [6:47:58<19:06:21, 88.41s/it]Training Progress:  22%|██▏       | 223/1000 [6:49:29<19:16:53, 89.33s/it]Training Progress:  22%|██▏       | 224/1000 [6:51:00<19:21:03, 89.77s/it]Training Progress:  22%|██▎       | 225/1000 [6:52:29<19:16:58, 89.57s/it]Training Progress:  23%|██▎       | 226/1000 [6:53:56<19:06:42, 88.89s/it]Training Progress:  23%|██▎       | 227/1000 [6:55:29<19:21:28, 90.15s/it]Training Progress:  23%|██▎       | 228/1000 [6:56:57<19:09:20, 89.33s/it]Training Progress:  23%|██▎       | 229/1000 [6:58:25<19:01:56, 88.87s/it]Training Progress:  23%|██▎       | 230/1000 [6:59:52<18:54:02, 88.37s/it]  Found better model: Training loss improved from 0.001974 to 0.001869
Training Progress:  23%|██▎       | 231/1000 [7:01:20<18:52:20, 88.35s/it]Training Progress:  23%|██▎       | 232/1000 [7:02:51<19:01:25, 89.17s/it]Training Progress:  23%|██▎       | 233/1000 [7:04:23<19:08:50, 89.87s/it]Training Progress:  23%|██▎       | 234/1000 [7:05:50<18:55:59, 88.98s/it]Training Progress:  24%|██▎       | 235/1000 [7:07:17<18:47:40, 88.44s/it]Training Progress:  24%|██▎       | 236/1000 [7:08:43<18:37:15, 87.74s/it]Training Progress:  24%|██▎       | 237/1000 [7:10:11<18:37:32, 87.88s/it]Training Progress:  24%|██▍       | 238/1000 [7:11:36<18:25:28, 87.04s/it]Training Progress:  24%|██▍       | 239/1000 [7:13:05<18:31:51, 87.66s/it]Training Progress:  24%|██▍       | 240/1000 [7:14:36<18:40:01, 88.42s/it]  Found better model: Training loss improved from 0.001869 to 0.001719
Training Progress:  24%|██▍       | 241/1000 [7:16:05<18:44:08, 88.86s/it]Training Progress:  24%|██▍       | 242/1000 [7:17:34<18:40:32, 88.70s/it]Training Progress:  24%|██▍       | 243/1000 [7:19:01<18:34:10, 88.31s/it]Training Progress:  24%|██▍       | 244/1000 [7:20:31<18:40:11, 88.90s/it]Training Progress:  24%|██▍       | 245/1000 [7:22:00<18:36:49, 88.75s/it]Training Progress:  25%|██▍       | 246/1000 [7:23:30<18:40:24, 89.16s/it]Training Progress:  25%|██▍       | 247/1000 [7:24:56<18:28:32, 88.33s/it]Training Progress:  25%|██▍       | 248/1000 [7:26:29<18:43:53, 89.67s/it]Training Progress:  25%|██▍       | 249/1000 [7:27:59<18:43:14, 89.74s/it]Training Progress:  25%|██▌       | 250/1000 [7:29:29<18:41:59, 89.76s/it]  Found better model: Training loss improved from 0.001719 to 0.001600
Training Progress:  25%|██▌       | 251/1000 [7:31:01<18:50:43, 90.58s/it]Training Progress:  25%|██▌       | 252/1000 [7:32:29<18:38:05, 89.69s/it]Training Progress:  25%|██▌       | 253/1000 [7:33:57<18:29:56, 89.15s/it]Training Progress:  25%|██▌       | 254/1000 [7:35:23<18:17:48, 88.30s/it]Training Progress:  26%|██▌       | 255/1000 [7:36:55<18:28:15, 89.26s/it]Training Progress:  26%|██▌       | 256/1000 [7:38:26<18:36:35, 90.05s/it]Training Progress:  26%|██▌       | 257/1000 [7:39:57<18:36:02, 90.12s/it]Training Progress:  26%|██▌       | 258/1000 [7:41:25<18:27:25, 89.55s/it]Training Progress:  26%|██▌       | 259/1000 [7:42:55<18:27:56, 89.71s/it]Training Progress:  26%|██▌       | 260/1000 [7:44:23<18:19:23, 89.14s/it]  Found better model: Training loss improved from 0.001600 to 0.001412
Training Progress:  26%|██▌       | 261/1000 [7:45:53<18:22:55, 89.55s/it]Training Progress:  26%|██▌       | 262/1000 [7:47:23<18:21:15, 89.53s/it]Training Progress:  26%|██▋       | 263/1000 [7:48:51<18:14:28, 89.10s/it]Training Progress:  26%|██▋       | 264/1000 [7:50:16<17:56:47, 87.78s/it]Training Progress:  26%|██▋       | 265/1000 [7:51:43<17:52:05, 87.52s/it]Training Progress:  27%|██▋       | 266/1000 [7:53:09<17:46:53, 87.21s/it]Training Progress:  27%|██▋       | 267/1000 [7:54:37<17:46:53, 87.33s/it]Training Progress:  27%|██▋       | 268/1000 [7:56:08<17:59:34, 88.49s/it]Training Progress:  27%|██▋       | 269/1000 [7:57:36<17:57:02, 88.40s/it]Training Progress:  27%|██▋       | 270/1000 [7:59:05<17:58:29, 88.64s/it]  Found better model: Training loss improved from 0.001412 to 0.001267
Training Progress:  27%|██▋       | 271/1000 [8:00:32<17:49:54, 88.06s/it]Training Progress:  27%|██▋       | 272/1000 [8:01:59<17:43:29, 87.65s/it]Training Progress:  27%|██▋       | 273/1000 [8:03:29<17:51:39, 88.45s/it]Training Progress:  27%|██▋       | 274/1000 [8:05:01<18:04:55, 89.66s/it]Training Progress:  28%|██▊       | 275/1000 [8:06:33<18:09:43, 90.18s/it]Training Progress:  28%|██▊       | 276/1000 [8:07:59<17:52:21, 88.87s/it]Training Progress:  28%|██▊       | 277/1000 [8:09:27<17:49:53, 88.79s/it]Training Progress:  28%|██▊       | 278/1000 [8:10:56<17:47:23, 88.70s/it]Training Progress:  28%|██▊       | 279/1000 [8:12:23<17:41:54, 88.37s/it]Training Progress:  28%|██▊       | 280/1000 [8:13:56<17:56:46, 89.73s/it]  Found better model: Training loss improved from 0.001267 to 0.001131
Training Progress:  28%|██▊       | 281/1000 [8:15:23<17:44:22, 88.82s/it]Training Progress:  28%|██▊       | 282/1000 [8:16:53<17:46:45, 89.14s/it]Training Progress:  28%|██▊       | 283/1000 [8:18:22<17:45:28, 89.16s/it]Training Progress:  28%|██▊       | 284/1000 [8:19:51<17:44:08, 89.17s/it]Training Progress:  28%|██▊       | 285/1000 [8:21:19<17:37:21, 88.73s/it]Training Progress:  29%|██▊       | 286/1000 [8:22:49<17:40:25, 89.11s/it]Training Progress:  29%|██▊       | 287/1000 [8:24:17<17:34:58, 88.78s/it]Training Progress:  29%|██▉       | 288/1000 [8:25:50<17:49:36, 90.14s/it]Training Progress:  29%|██▉       | 289/1000 [8:27:20<17:44:46, 89.86s/it]Training Progress:  29%|██▉       | 290/1000 [8:28:46<17:32:05, 88.91s/it]  Found better model: Training loss improved from 0.001131 to 0.001034
Training Progress:  29%|██▉       | 291/1000 [8:30:12<17:19:34, 87.98s/it]Training Progress:  29%|██▉       | 292/1000 [8:31:44<17:30:57, 89.06s/it]Training Progress:  29%|██▉       | 293/1000 [8:33:15<17:36:17, 89.64s/it]Training Progress:  29%|██▉       | 294/1000 [8:34:46<17:39:56, 90.08s/it]Training Progress:  30%|██▉       | 295/1000 [8:36:13<17:28:39, 89.25s/it]Training Progress:  30%|██▉       | 296/1000 [8:37:42<17:25:36, 89.11s/it]Training Progress:  30%|██▉       | 297/1000 [8:39:12<17:28:59, 89.53s/it]Training Progress:  30%|██▉       | 298/1000 [8:40:38<17:15:05, 88.47s/it]Training Progress:  30%|██▉       | 299/1000 [8:42:08<17:16:53, 88.75s/it]Training Progress:  30%|███       | 300/1000 [8:43:36<17:14:10, 88.64s/it]  Found better model: Training loss improved from 0.001034 to 0.000965
Epoch 300: Train=0.000965, Best Train=0.000965
Training Progress:  30%|███       | 301/1000 [8:45:02<17:03:48, 87.88s/it]Training Progress:  30%|███       | 302/1000 [8:46:34<17:15:20, 89.00s/it]Training Progress:  30%|███       | 303/1000 [8:48:04<17:18:23, 89.39s/it]Training Progress:  30%|███       | 304/1000 [8:49:32<17:12:03, 88.97s/it]Training Progress:  30%|███       | 305/1000 [8:51:01<17:09:17, 88.86s/it]Training Progress:  31%|███       | 306/1000 [8:52:31<17:11:24, 89.17s/it]Training Progress:  31%|███       | 307/1000 [8:53:59<17:08:39, 89.06s/it]Training Progress:  31%|███       | 308/1000 [8:55:29<17:08:41, 89.19s/it]Training Progress:  31%|███       | 309/1000 [8:56:56<17:00:19, 88.60s/it]Training Progress:  31%|███       | 310/1000 [8:58:27<17:07:08, 89.32s/it]  Found better model: Training loss improved from 0.000965 to 0.000906
Training Progress:  31%|███       | 311/1000 [8:59:55<17:00:04, 88.83s/it]Training Progress:  31%|███       | 312/1000 [9:01:25<17:03:59, 89.30s/it]Training Progress:  31%|███▏      | 313/1000 [9:02:51<16:49:05, 88.13s/it]Training Progress:  31%|███▏      | 314/1000 [9:04:19<16:49:56, 88.33s/it]Training Progress:  32%|███▏      | 315/1000 [9:05:52<17:02:03, 89.52s/it]Training Progress:  32%|███▏      | 316/1000 [9:07:17<16:45:25, 88.20s/it]Training Progress:  32%|███▏      | 317/1000 [9:08:47<16:50:07, 88.74s/it]Training Progress:  32%|███▏      | 318/1000 [9:10:19<17:01:28, 89.87s/it]Training Progress:  32%|███▏      | 319/1000 [9:11:46<16:49:52, 88.98s/it]Training Progress:  32%|███▏      | 320/1000 [9:13:16<16:52:34, 89.35s/it]  Found better model: Training loss improved from 0.000906 to 0.000848
Training Progress:  32%|███▏      | 321/1000 [9:14:47<16:53:58, 89.60s/it]Training Progress:  32%|███▏      | 322/1000 [9:16:12<16:38:15, 88.34s/it]Training Progress:  32%|███▏      | 323/1000 [9:17:40<16:36:36, 88.33s/it]Training Progress:  32%|███▏      | 324/1000 [9:19:07<16:30:19, 87.90s/it]Training Progress:  32%|███▎      | 325/1000 [9:20:38<16:39:21, 88.83s/it]Training Progress:  33%|███▎      | 326/1000 [9:22:07<16:36:03, 88.67s/it]Training Progress:  33%|███▎      | 327/1000 [9:23:39<16:46:27, 89.73s/it]Training Progress:  33%|███▎      | 328/1000 [9:25:06<16:35:26, 88.88s/it]Training Progress:  33%|███▎      | 329/1000 [9:26:28<16:13:14, 87.03s/it]Training Progress:  33%|███▎      | 330/1000 [9:27:55<16:10:42, 86.93s/it]  Found better model: Training loss improved from 0.000848 to 0.000826
Training Progress:  33%|███▎      | 331/1000 [9:29:25<16:19:52, 87.88s/it]Training Progress:  33%|███▎      | 332/1000 [9:30:53<16:17:07, 87.77s/it]Training Progress:  33%|███▎      | 333/1000 [9:32:20<16:14:46, 87.69s/it]Training Progress:  33%|███▎      | 334/1000 [9:33:53<16:30:42, 89.25s/it]Training Progress:  34%|███▎      | 335/1000 [9:35:24<16:36:00, 89.87s/it]Training Progress:  34%|███▎      | 336/1000 [9:36:49<16:16:42, 88.26s/it]Training Progress:  34%|███▎      | 337/1000 [9:38:19<16:20:59, 88.78s/it]Training Progress:  34%|███▍      | 338/1000 [9:39:45<16:10:39, 87.98s/it]Training Progress:  34%|███▍      | 339/1000 [9:41:15<16:16:12, 88.61s/it]Training Progress:  34%|███▍      | 340/1000 [9:42:46<16:22:17, 89.30s/it]  Found better model: Training loss improved from 0.000826 to 0.000799
Training Progress:  34%|███▍      | 341/1000 [9:44:12<16:08:56, 88.22s/it]Training Progress:  34%|███▍      | 342/1000 [9:45:39<16:05:45, 88.06s/it]Training Progress:  34%|███▍      | 343/1000 [9:47:06<16:00:47, 87.74s/it]Training Progress:  34%|███▍      | 344/1000 [9:48:34<15:59:12, 87.73s/it]Training Progress:  34%|███▍      | 345/1000 [9:50:02<15:58:56, 87.84s/it]Training Progress:  35%|███▍      | 346/1000 [9:51:32<16:04:31, 88.49s/it]Training Progress:  35%|███▍      | 347/1000 [9:53:00<16:00:10, 88.22s/it]Training Progress:  35%|███▍      | 348/1000 [9:54:31<16:07:44, 89.06s/it]Training Progress:  35%|███▍      | 349/1000 [9:55:56<15:53:03, 87.84s/it]Training Progress:  35%|███▌      | 350/1000 [9:57:29<16:07:42, 89.33s/it]  Found better model: Training loss improved from 0.000799 to 0.000767
Training Progress:  35%|███▌      | 351/1000 [9:58:59<16:09:42, 89.65s/it]Training Progress:  35%|███▌      | 352/1000 [10:00:26<16:00:36, 88.94s/it]Training Progress:  35%|███▌      | 353/1000 [10:02:01<16:17:44, 90.67s/it]Training Progress:  35%|███▌      | 354/1000 [10:03:27<16:01:27, 89.30s/it]Training Progress:  36%|███▌      | 355/1000 [10:04:55<15:55:26, 88.88s/it]Training Progress:  36%|███▌      | 356/1000 [10:06:27<16:03:43, 89.79s/it]Training Progress:  36%|███▌      | 357/1000 [10:07:54<15:53:34, 88.98s/it]Training Progress:  36%|███▌      | 358/1000 [10:09:23<15:53:43, 89.13s/it]Training Progress:  36%|███▌      | 359/1000 [10:10:56<16:04:19, 90.26s/it]Training Progress:  36%|███▌      | 360/1000 [10:12:26<16:00:03, 90.01s/it]  Found better model: Training loss improved from 0.000767 to 0.000742
Training Progress:  36%|███▌      | 361/1000 [10:13:52<15:47:21, 88.95s/it]Training Progress:  36%|███▌      | 362/1000 [10:15:22<15:47:17, 89.09s/it]Training Progress:  36%|███▋      | 363/1000 [10:16:53<15:52:12, 89.69s/it]Training Progress:  36%|███▋      | 364/1000 [10:18:24<15:56:10, 90.20s/it]Training Progress:  36%|███▋      | 365/1000 [10:19:51<15:44:28, 89.24s/it]Training Progress:  37%|███▋      | 366/1000 [10:21:21<15:46:40, 89.59s/it]Training Progress:  37%|███▋      | 367/1000 [10:22:46<15:29:22, 88.09s/it]Training Progress:  37%|███▋      | 368/1000 [10:24:14<15:26:40, 87.98s/it]Training Progress:  37%|███▋      | 369/1000 [10:25:42<15:26:32, 88.10s/it]Training Progress:  37%|███▋      | 370/1000 [10:27:07<15:15:56, 87.23s/it]  Found better model: Training loss improved from 0.000742 to 0.000732
Training Progress:  37%|███▋      | 371/1000 [10:28:31<15:02:25, 86.08s/it]Training Progress:  37%|███▋      | 372/1000 [10:30:01<15:13:37, 87.29s/it]Training Progress:  37%|███▋      | 373/1000 [10:31:32<15:24:25, 88.46s/it]Training Progress:  37%|███▋      | 374/1000 [10:33:02<15:29:00, 89.04s/it]Training Progress:  38%|███▊      | 375/1000 [10:34:28<15:17:23, 88.07s/it]Training Progress:  38%|███▊      | 376/1000 [10:35:58<15:19:45, 88.44s/it]Training Progress:  38%|███▊      | 377/1000 [10:37:24<15:11:37, 87.80s/it]Training Progress:  38%|███▊      | 378/1000 [10:38:52<15:11:07, 87.89s/it]Training Progress:  38%|███▊      | 379/1000 [10:40:17<15:01:18, 87.08s/it]Training Progress:  38%|███▊      | 380/1000 [10:41:48<15:11:02, 88.17s/it]  Found better model: Training loss improved from 0.000732 to 0.000707
Training Progress:  38%|███▊      | 381/1000 [10:43:18<15:14:57, 88.69s/it]Training Progress:  38%|███▊      | 382/1000 [10:44:48<15:18:27, 89.17s/it]Training Progress:  38%|███▊      | 383/1000 [10:46:23<15:35:52, 91.01s/it]Training Progress:  38%|███▊      | 384/1000 [10:47:51<15:24:28, 90.05s/it]Training Progress:  38%|███▊      | 385/1000 [10:49:17<15:10:32, 88.83s/it]Training Progress:  39%|███▊      | 386/1000 [10:50:45<15:05:52, 88.52s/it]Training Progress:  39%|███▊      | 387/1000 [10:52:13<15:03:24, 88.42s/it]Training Progress:  39%|███▉      | 388/1000 [10:53:41<15:00:03, 88.24s/it]Training Progress:  39%|███▉      | 389/1000 [10:55:10<15:01:30, 88.53s/it]Training Progress:  39%|███▉      | 390/1000 [10:56:37<14:54:08, 87.95s/it]  Found better model: Training loss improved from 0.000707 to 0.000691
Training Progress:  39%|███▉      | 391/1000 [10:58:06<14:57:41, 88.44s/it]Training Progress:  39%|███▉      | 392/1000 [10:59:34<14:54:16, 88.25s/it]Training Progress:  39%|███▉      | 393/1000 [11:01:01<14:47:11, 87.70s/it]Training Progress:  39%|███▉      | 394/1000 [11:02:30<14:50:16, 88.15s/it]Training Progress:  40%|███▉      | 395/1000 [11:03:58<14:48:59, 88.16s/it]Training Progress:  40%|███▉      | 396/1000 [11:05:25<14:44:35, 87.87s/it]Training Progress:  40%|███▉      | 397/1000 [11:06:57<14:56:09, 89.17s/it]Training Progress:  40%|███▉      | 398/1000 [11:08:24<14:46:38, 88.37s/it]Training Progress:  40%|███▉      | 399/1000 [11:09:55<14:53:59, 89.25s/it]Training Progress:  40%|████      | 400/1000 [11:11:23<14:46:56, 88.69s/it]  Found better model: Training loss improved from 0.000691 to 0.000662
Epoch 400: Train=0.000662, Best Train=0.000662
Training Progress:  40%|████      | 401/1000 [11:12:53<14:49:41, 89.12s/it]Training Progress:  40%|████      | 402/1000 [11:14:23<14:50:14, 89.32s/it]Training Progress:  40%|████      | 403/1000 [11:15:48<14:37:38, 88.21s/it]Training Progress:  40%|████      | 404/1000 [11:17:14<14:29:00, 87.48s/it]Training Progress:  40%|████      | 405/1000 [11:18:45<14:39:11, 88.66s/it]Training Progress:  41%|████      | 406/1000 [11:20:16<14:43:46, 89.27s/it]Training Progress:  41%|████      | 407/1000 [11:21:46<14:45:21, 89.58s/it]Training Progress:  41%|████      | 408/1000 [11:23:17<14:46:33, 89.85s/it]Training Progress:  41%|████      | 409/1000 [11:24:42<14:31:02, 88.43s/it]Training Progress:  41%|████      | 410/1000 [11:26:11<14:32:41, 88.75s/it]  Found better model: Training loss improved from 0.000662 to 0.000654
Training Progress:  41%|████      | 411/1000 [11:27:39<14:28:08, 88.44s/it]Training Progress:  41%|████      | 412/1000 [11:29:10<14:35:04, 89.29s/it]Training Progress:  41%|████▏     | 413/1000 [11:30:40<14:34:46, 89.42s/it]Training Progress:  41%|████▏     | 414/1000 [11:32:11<14:38:31, 89.95s/it]Training Progress:  42%|████▏     | 415/1000 [11:33:39<14:31:01, 89.34s/it]Training Progress:  42%|████▏     | 416/1000 [11:35:09<14:29:26, 89.33s/it]Training Progress:  42%|████▏     | 417/1000 [11:36:37<14:25:31, 89.08s/it]Training Progress:  42%|████▏     | 418/1000 [11:38:06<14:23:15, 89.00s/it]Training Progress:  42%|████▏     | 419/1000 [11:39:35<14:20:54, 88.91s/it]Training Progress:  42%|████▏     | 420/1000 [11:41:07<14:28:23, 89.83s/it]  Found better model: Training loss improved from 0.000654 to 0.000638
Training Progress:  42%|████▏     | 421/1000 [11:42:33<14:18:24, 88.95s/it]Training Progress:  42%|████▏     | 422/1000 [11:44:01<14:11:34, 88.40s/it]Training Progress:  42%|████▏     | 423/1000 [11:45:30<14:14:07, 88.82s/it]Training Progress:  42%|████▏     | 424/1000 [11:46:59<14:11:44, 88.72s/it]Training Progress:  42%|████▎     | 425/1000 [11:48:27<14:07:36, 88.45s/it]Training Progress:  43%|████▎     | 426/1000 [11:49:54<14:03:59, 88.22s/it]Training Progress:  43%|████▎     | 427/1000 [11:51:20<13:55:34, 87.49s/it]Training Progress:  43%|████▎     | 428/1000 [11:52:49<13:58:08, 87.92s/it]Training Progress:  43%|████▎     | 429/1000 [11:54:37<14:52:53, 93.82s/it]Training Progress:  43%|████▎     | 430/1000 [11:56:19<15:16:36, 96.48s/it]  Found better model: Training loss improved from 0.000638 to 0.000626
Training Progress:  43%|████▎     | 431/1000 [11:57:57<15:18:44, 96.88s/it]Training Progress:  43%|████▎     | 432/1000 [11:59:41<15:36:48, 98.96s/it]Training Progress:  43%|████▎     | 433/1000 [12:01:25<15:50:33, 100.59s/it]Training Progress:  43%|████▎     | 434/1000 [12:03:08<15:54:53, 101.23s/it]Training Progress:  43%|████▎     | 434/1000 [12:03:59<15:44:11, 100.09s/it]
Pipeline execution failed: The pointer[value] is null.

----------------------------------------------------
- Framework Unexpected Exception Raised:
----------------------------------------------------
This exception is caused by framework's unexpected error. Please create an issue at https://gitee.com/mindspore/mindspore/issues to get help.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/ccsrc/pipeline/pynative/grad/auto_grad.cc:149 BuildSpecialNode

Traceback (most recent call last):
  File "train.py", line 981, in run_complete_pipeline
    final_loss = self.train_model()
  File "train.py", line 607, in train_model
    train_loss = train_net(batch_input, batch_output)
  File "/inspire/ssd/project/wuliqifa/wangruocheng-253108120166/miniconda3/envs/mindquan/lib/python3.7/site-packages/mindspore/nn/cell.py", line 705, in __call__
    raise err
  File "/inspire/ssd/project/wuliqifa/wangruocheng-253108120166/miniconda3/envs/mindquan/lib/python3.7/site-packages/mindspore/nn/cell.py", line 701, in __call__
    output = self._run_construct(args, kwargs)
  File "/inspire/ssd/project/wuliqifa/wangruocheng-253108120166/miniconda3/envs/mindquan/lib/python3.7/site-packages/mindspore/nn/cell.py", line 482, in _run_construct
    output = self.construct(*cast_inputs, **kwargs)
  File "/inspire/ssd/project/wuliqifa/wangruocheng-253108120166/miniconda3/envs/mindquan/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py", line 418, in construct
    return self._no_sens_impl(*inputs)
  File "/inspire/ssd/project/wuliqifa/wangruocheng-253108120166/miniconda3/envs/mindquan/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py", line 434, in _no_sens_impl
    grads = self.grad_no_sens(self.network, self.weights)(*inputs)
  File "/inspire/ssd/project/wuliqifa/wangruocheng-253108120166/miniconda3/envs/mindquan/lib/python3.7/site-packages/mindspore/ops/composite/base.py", line 388, in after_grad
    return grad_(fn, weights)(*args, **kwargs)
  File "/inspire/ssd/project/wuliqifa/wangruocheng-253108120166/miniconda3/envs/mindquan/lib/python3.7/site-packages/mindspore/common/api.py", line 121, in wrapper
    results = fn(*arg, **kwargs)
  File "/inspire/ssd/project/wuliqifa/wangruocheng-253108120166/miniconda3/envs/mindquan/lib/python3.7/site-packages/mindspore/ops/composite/base.py", line 377, in after_grad
    _pynative_executor.grad(fn, grad_, weights, self.grad_position, *args, **kwargs)
  File "/inspire/ssd/project/wuliqifa/wangruocheng-253108120166/miniconda3/envs/mindquan/lib/python3.7/site-packages/mindspore/common/api.py", line 1249, in grad
    self._executor.grad_net(grad, obj, weights, grad_position, *args, *(kwargs.values()))
RuntimeError: The pointer[value] is null.

----------------------------------------------------
- Framework Unexpected Exception Raised:
----------------------------------------------------
This exception is caused by framework's unexpected error. Please create an issue at https://gitee.com/mindspore/mindspore/issues to get help.

----------------------------------------------------
- C++ Call Stack: (For framework developers)
----------------------------------------------------
mindspore/ccsrc/pipeline/pynative/grad/auto_grad.cc:149 BuildSpecialNode

Training failed
