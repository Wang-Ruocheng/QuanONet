{
  "MSE": 0.0006860850554130594,
  "MAE": 0.020104312832001595,
  "Max_Error": 0.17533142864704132,
  "config": {
    "// Universal ODE operator configuration file": "config_ODE.json",
    "// Supported operator types": [
      "Inverse",
      "Homogeneous",
      "Nonlinear",
      "Custom"
    ],
    "// Data generation parameters": "",
    "num_train": 1000,
    "num_test": 1000,
    "num_points": 100,
    "train_sample_num": 10,
    "test_sample_num": 100,
    "length_scale": 0.2,
    "num_cal": 1000,
    "// Model parameters": "",
    "branch_input_size": 100,
    "trunk_input_size": 1,
    "output_size": 1,
    "num_qubits": 2,
    "net_size": [
      300,
      2,
      10,
      2
    ],
    "scale_coeff": 0.001,
    "model_type": "QuanONet",
    "if_trainable_freq": true,
    "// Training parameters": "",
    "learning_rate": 0.0001,
    "num_epochs": 1000,
    "target_error": 1e-10,
    "batch_size": 100,
    "validation_split": 0,
    "patience": 20,
    "// Operator-specific parameters": "",
    "custom_name": null,
    "custom_ode_description": "Only used when operator_type=Custom, specify via command line --custom_ode",
    "operator_type": "Inverse",
    "random_seed": 1
  },
  "training_history": [
    {
      "epoch": 0,
      "train_loss": 0.06402334380894899
    },
    {
      "epoch": 10,
      "train_loss": 0.011927197766490281
    },
    {
      "epoch": 20,
      "train_loss": 0.010227723992429674
    },
    {
      "epoch": 30,
      "train_loss": 0.009577889465726913
    },
    {
      "epoch": 40,
      "train_loss": 0.008472191346809268
    },
    {
      "epoch": 50,
      "train_loss": 0.0069169960031285884
    },
    {
      "epoch": 60,
      "train_loss": 0.0056827119761146605
    },
    {
      "epoch": 70,
      "train_loss": 0.004104888408910483
    },
    {
      "epoch": 80,
      "train_loss": 0.0035778398683760314
    },
    {
      "epoch": 90,
      "train_loss": 0.003147781370207667
    },
    {
      "epoch": 100,
      "train_loss": 0.003097979070153087
    },
    {
      "epoch": 110,
      "train_loss": 0.00289900966337882
    },
    {
      "epoch": 120,
      "train_loss": 0.0029354192479513585
    },
    {
      "epoch": 130,
      "train_loss": 0.002717685676179826
    },
    {
      "epoch": 140,
      "train_loss": 0.002768659145804122
    },
    {
      "epoch": 150,
      "train_loss": 0.0028552455629687755
    },
    {
      "epoch": 160,
      "train_loss": 0.002487774401670322
    },
    {
      "epoch": 170,
      "train_loss": 0.002254450763575733
    },
    {
      "epoch": 180,
      "train_loss": 0.0022025274491170423
    },
    {
      "epoch": 190,
      "train_loss": 0.0019736914988607167
    },
    {
      "epoch": 200,
      "train_loss": 0.0017352416767971591
    },
    {
      "epoch": 210,
      "train_loss": 0.0017483840748900548
    },
    {
      "epoch": 220,
      "train_loss": 0.0014923957671271638
    },
    {
      "epoch": 230,
      "train_loss": 0.001345290121389553
    },
    {
      "epoch": 240,
      "train_loss": 0.0012373037880752235
    },
    {
      "epoch": 250,
      "train_loss": 0.0010660333232954144
    },
    {
      "epoch": 260,
      "train_loss": 0.0012281377741601319
    },
    {
      "epoch": 270,
      "train_loss": 0.0010172096715541556
    },
    {
      "epoch": 280,
      "train_loss": 0.0010896722064353526
    },
    {
      "epoch": 290,
      "train_loss": 0.001106117882882245
    },
    {
      "epoch": 300,
      "train_loss": 0.0009825513907708227
    },
    {
      "epoch": 310,
      "train_loss": 0.001066465811454691
    },
    {
      "epoch": 320,
      "train_loss": 0.0009237075981218367
    },
    {
      "epoch": 330,
      "train_loss": 0.0009496800845954567
    },
    {
      "epoch": 340,
      "train_loss": 0.0010151364596094935
    },
    {
      "epoch": 350,
      "train_loss": 0.0009611908224178478
    },
    {
      "epoch": 360,
      "train_loss": 0.0009486825898056849
    },
    {
      "epoch": 370,
      "train_loss": 0.0008611595712136477
    },
    {
      "epoch": 380,
      "train_loss": 0.0012375386932399124
    },
    {
      "epoch": 390,
      "train_loss": 0.0008739260619040579
    },
    {
      "epoch": 400,
      "train_loss": 0.0008818588568829
    },
    {
      "epoch": 410,
      "train_loss": 0.0008680422388715669
    },
    {
      "epoch": 420,
      "train_loss": 0.00090912623971235
    },
    {
      "epoch": 430,
      "train_loss": 0.0008820971776731312
    },
    {
      "epoch": 440,
      "train_loss": 0.0008740045799640938
    },
    {
      "epoch": 450,
      "train_loss": 0.0012064819675288163
    },
    {
      "epoch": 460,
      "train_loss": 0.0008363759866915643
    },
    {
      "epoch": 470,
      "train_loss": 0.0008874843118246645
    },
    {
      "epoch": 480,
      "train_loss": 0.0009122240776196122
    },
    {
      "epoch": 490,
      "train_loss": 0.0009274788625771179
    },
    {
      "epoch": 500,
      "train_loss": 0.0008564853662392125
    },
    {
      "epoch": 510,
      "train_loss": 0.0008697390789166093
    },
    {
      "epoch": 520,
      "train_loss": 0.0009500203083734959
    },
    {
      "epoch": 530,
      "train_loss": 0.0008342407995951362
    },
    {
      "epoch": 540,
      "train_loss": 0.0009754082208382897
    },
    {
      "epoch": 550,
      "train_loss": 0.0008979714944143779
    },
    {
      "epoch": 560,
      "train_loss": 0.0008336819079704582
    },
    {
      "epoch": 570,
      "train_loss": 0.000847651555086486
    },
    {
      "epoch": 580,
      "train_loss": 0.0008548538945615292
    },
    {
      "epoch": 590,
      "train_loss": 0.001013710803235881
    },
    {
      "epoch": 600,
      "train_loss": 0.000877868722891435
    },
    {
      "epoch": 610,
      "train_loss": 0.0008338552934583276
    },
    {
      "epoch": 620,
      "train_loss": 0.0009065612423000858
    },
    {
      "epoch": 630,
      "train_loss": 0.0009183546743588522
    },
    {
      "epoch": 640,
      "train_loss": 0.000993910834658891
    },
    {
      "epoch": 650,
      "train_loss": 0.0008088278531795368
    },
    {
      "epoch": 660,
      "train_loss": 0.0008718066208530217
    },
    {
      "epoch": 670,
      "train_loss": 0.0008202490056282841
    },
    {
      "epoch": 680,
      "train_loss": 0.0008236834331182763
    },
    {
      "epoch": 690,
      "train_loss": 0.0012101082410663367
    },
    {
      "epoch": 700,
      "train_loss": 0.0009174799622269348
    },
    {
      "epoch": 710,
      "train_loss": 0.0009512522205477581
    },
    {
      "epoch": 720,
      "train_loss": 0.0007299206394236535
    },
    {
      "epoch": 730,
      "train_loss": 0.0009097452630521729
    },
    {
      "epoch": 740,
      "train_loss": 0.0009281321603339165
    },
    {
      "epoch": 750,
      "train_loss": 0.0008274501116829925
    },
    {
      "epoch": 760,
      "train_loss": 0.0007904539498849772
    },
    {
      "epoch": 770,
      "train_loss": 0.0009050073812250048
    },
    {
      "epoch": 780,
      "train_loss": 0.0008282358094584196
    },
    {
      "epoch": 790,
      "train_loss": 0.001023528371588327
    },
    {
      "epoch": 800,
      "train_loss": 0.0007920193011523224
    },
    {
      "epoch": 810,
      "train_loss": 0.0008267139023519121
    },
    {
      "epoch": 820,
      "train_loss": 0.0009896850129007362
    },
    {
      "epoch": 830,
      "train_loss": 0.0007351071492303163
    },
    {
      "epoch": 840,
      "train_loss": 0.0007999755360651762
    },
    {
      "epoch": 850,
      "train_loss": 0.0007709133805474266
    },
    {
      "epoch": 860,
      "train_loss": 0.000847580518166069
    },
    {
      "epoch": 870,
      "train_loss": 0.0007430040067993105
    },
    {
      "epoch": 880,
      "train_loss": 0.0007844072650186717
    },
    {
      "epoch": 890,
      "train_loss": 0.0008257695316569879
    },
    {
      "epoch": 900,
      "train_loss": 0.0009969167536473833
    },
    {
      "epoch": 910,
      "train_loss": 0.0007569359123590402
    },
    {
      "epoch": 920,
      "train_loss": 0.0009145082972827367
    },
    {
      "epoch": 930,
      "train_loss": 0.0008388258013292216
    },
    {
      "epoch": 940,
      "train_loss": 0.0007861597667215392
    },
    {
      "epoch": 950,
      "train_loss": 0.0008353313358384184
    },
    {
      "epoch": 960,
      "train_loss": 0.0008657656339346432
    },
    {
      "epoch": 970,
      "train_loss": 0.0008124449299066328
    },
    {
      "epoch": 980,
      "train_loss": 0.00073217585333623
    },
    {
      "epoch": 990,
      "train_loss": 0.0009845377033343538
    }
  ]
}