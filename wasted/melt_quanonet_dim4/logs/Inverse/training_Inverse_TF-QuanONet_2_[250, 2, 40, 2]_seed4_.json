{
  "MSE": 0.00021198480625025695,
  "MAE": 0.01110690431005787,
  "Max_Error": 0.09608794003725052,
  "config": {
    "// Universal ODE operator configuration file": "config_ODE.json",
    "// Supported operator types": [
      "Inverse",
      "Homogeneous",
      "Nonlinear",
      "Custom"
    ],
    "// Data generation parameters": "",
    "num_train": 1000,
    "num_test": 1000,
    "num_points": 100,
    "train_sample_num": 10,
    "test_sample_num": 100,
    "length_scale": 0.2,
    "num_cal": 1000,
    "// Model parameters": "",
    "branch_input_size": 100,
    "trunk_input_size": 1,
    "output_size": 1,
    "num_qubits": 2,
    "net_size": [
      250,
      2,
      40,
      2
    ],
    "scale_coeff": 0.001,
    "model_type": "QuanONet",
    "if_trainable_freq": true,
    "// Training parameters": "",
    "learning_rate": 0.0001,
    "num_epochs": 1000,
    "target_error": 1e-10,
    "batch_size": 100,
    "validation_split": 0,
    "patience": 20,
    "// Operator-specific parameters": "",
    "custom_name": null,
    "custom_ode_description": "Only used when operator_type=Custom, specify via command line --custom_ode",
    "operator_type": "Inverse",
    "random_seed": 4
  },
  "training_history": [
    {
      "epoch": 0,
      "train_loss": 0.08571485638618469
    },
    {
      "epoch": 10,
      "train_loss": 0.009393911720253527
    },
    {
      "epoch": 20,
      "train_loss": 0.009151994474232197
    },
    {
      "epoch": 30,
      "train_loss": 0.007920242720283568
    },
    {
      "epoch": 40,
      "train_loss": 0.005219349400140345
    },
    {
      "epoch": 50,
      "train_loss": 0.003738288420718163
    },
    {
      "epoch": 60,
      "train_loss": 0.0030797478463500737
    },
    {
      "epoch": 70,
      "train_loss": 0.0026024637406226246
    },
    {
      "epoch": 80,
      "train_loss": 0.0023137067735660823
    },
    {
      "epoch": 90,
      "train_loss": 0.0019569413922727106
    },
    {
      "epoch": 100,
      "train_loss": 0.001567567500169389
    },
    {
      "epoch": 110,
      "train_loss": 0.0012563759426120669
    },
    {
      "epoch": 120,
      "train_loss": 0.001107223437866196
    },
    {
      "epoch": 130,
      "train_loss": 0.0008879409061046317
    },
    {
      "epoch": 140,
      "train_loss": 0.000869662951445207
    },
    {
      "epoch": 150,
      "train_loss": 0.0008175114047480747
    },
    {
      "epoch": 160,
      "train_loss": 0.0008847549255006016
    },
    {
      "epoch": 170,
      "train_loss": 0.000829051804030314
    },
    {
      "epoch": 180,
      "train_loss": 0.0009008781122975051
    },
    {
      "epoch": 190,
      "train_loss": 0.0008995409280760214
    },
    {
      "epoch": 200,
      "train_loss": 0.0007673886936390772
    },
    {
      "epoch": 210,
      "train_loss": 0.0007990170834818855
    },
    {
      "epoch": 220,
      "train_loss": 0.0007424578347126953
    },
    {
      "epoch": 230,
      "train_loss": 0.0008082451921654865
    },
    {
      "epoch": 240,
      "train_loss": 0.0008172155974898488
    },
    {
      "epoch": 250,
      "train_loss": 0.000807365155487787
    },
    {
      "epoch": 260,
      "train_loss": 0.0008364806915051304
    },
    {
      "epoch": 270,
      "train_loss": 0.0007332091481657699
    },
    {
      "epoch": 280,
      "train_loss": 0.0007540737622184679
    },
    {
      "epoch": 290,
      "train_loss": 0.000770597511145752
    },
    {
      "epoch": 300,
      "train_loss": 0.0007666447293013334
    },
    {
      "epoch": 310,
      "train_loss": 0.0007263856308418326
    },
    {
      "epoch": 320,
      "train_loss": 0.0007617386890342459
    },
    {
      "epoch": 330,
      "train_loss": 0.000734953032224439
    },
    {
      "epoch": 340,
      "train_loss": 0.0008139877990470267
    },
    {
      "epoch": 350,
      "train_loss": 0.0007601888832869008
    },
    {
      "epoch": 360,
      "train_loss": 0.0007994080733624287
    },
    {
      "epoch": 370,
      "train_loss": 0.0007145335257519037
    },
    {
      "epoch": 380,
      "train_loss": 0.0007433111884165555
    },
    {
      "epoch": 390,
      "train_loss": 0.0007734101172536612
    },
    {
      "epoch": 400,
      "train_loss": 0.0007079595598042943
    },
    {
      "epoch": 410,
      "train_loss": 0.0007161651164642535
    },
    {
      "epoch": 420,
      "train_loss": 0.000687713936495129
    },
    {
      "epoch": 430,
      "train_loss": 0.000703722840116825
    },
    {
      "epoch": 440,
      "train_loss": 0.0006392267212504521
    },
    {
      "epoch": 450,
      "train_loss": 0.0006789241041406058
    },
    {
      "epoch": 460,
      "train_loss": 0.0007033657302963547
    },
    {
      "epoch": 470,
      "train_loss": 0.0006105649063829333
    },
    {
      "epoch": 480,
      "train_loss": 0.0006157747082761489
    },
    {
      "epoch": 490,
      "train_loss": 0.0006711105752037838
    },
    {
      "epoch": 500,
      "train_loss": 0.0006042117180186324
    },
    {
      "epoch": 510,
      "train_loss": 0.0005271616467507557
    },
    {
      "epoch": 520,
      "train_loss": 0.0006111708807293325
    },
    {
      "epoch": 530,
      "train_loss": 0.000521722485718783
    },
    {
      "epoch": 540,
      "train_loss": 0.000443819991487544
    },
    {
      "epoch": 550,
      "train_loss": 0.0004118092202406842
    },
    {
      "epoch": 560,
      "train_loss": 0.00037895076151471584
    },
    {
      "epoch": 570,
      "train_loss": 0.00034453654356184413
    },
    {
      "epoch": 580,
      "train_loss": 0.00040876810016925446
    },
    {
      "epoch": 590,
      "train_loss": 0.0003408758854493499
    },
    {
      "epoch": 600,
      "train_loss": 0.00037555749877355994
    },
    {
      "epoch": 610,
      "train_loss": 0.0003070042436593212
    },
    {
      "epoch": 620,
      "train_loss": 0.00032194325918680986
    },
    {
      "epoch": 630,
      "train_loss": 0.00035670193086843936
    },
    {
      "epoch": 640,
      "train_loss": 0.0002733884230838157
    },
    {
      "epoch": 650,
      "train_loss": 0.0002942906504904386
    },
    {
      "epoch": 660,
      "train_loss": 0.00033469628775492313
    },
    {
      "epoch": 670,
      "train_loss": 0.00030541481435648166
    },
    {
      "epoch": 680,
      "train_loss": 0.00031967416231054813
    },
    {
      "epoch": 690,
      "train_loss": 0.00030852270778268574
    },
    {
      "epoch": 700,
      "train_loss": 0.00024953110580099746
    },
    {
      "epoch": 710,
      "train_loss": 0.00031082970497664064
    },
    {
      "epoch": 720,
      "train_loss": 0.000325539495825069
    },
    {
      "epoch": 730,
      "train_loss": 0.00028699133385089225
    },
    {
      "epoch": 740,
      "train_loss": 0.0003199563073576428
    },
    {
      "epoch": 750,
      "train_loss": 0.0002583558777405415
    },
    {
      "epoch": 760,
      "train_loss": 0.0002464975741168018
    },
    {
      "epoch": 770,
      "train_loss": 0.0003443683464138303
    },
    {
      "epoch": 780,
      "train_loss": 0.00030055123250349424
    },
    {
      "epoch": 790,
      "train_loss": 0.00031567703634209464
    },
    {
      "epoch": 800,
      "train_loss": 0.00024109516554744913
    },
    {
      "epoch": 810,
      "train_loss": 0.00024138355372997468
    },
    {
      "epoch": 820,
      "train_loss": 0.0003566185866657179
    },
    {
      "epoch": 830,
      "train_loss": 0.00028067853418178856
    },
    {
      "epoch": 840,
      "train_loss": 0.0002455222239950672
    },
    {
      "epoch": 850,
      "train_loss": 0.0002993377730308566
    },
    {
      "epoch": 860,
      "train_loss": 0.0002788696343486663
    },
    {
      "epoch": 870,
      "train_loss": 0.00028483444286393935
    },
    {
      "epoch": 880,
      "train_loss": 0.00041666905250167477
    },
    {
      "epoch": 890,
      "train_loss": 0.00026755819344543853
    },
    {
      "epoch": 900,
      "train_loss": 0.00025056050304556266
    },
    {
      "epoch": 910,
      "train_loss": 0.00022125481278635563
    },
    {
      "epoch": 920,
      "train_loss": 0.00033068400123738685
    },
    {
      "epoch": 930,
      "train_loss": 0.0002668948056816589
    },
    {
      "epoch": 940,
      "train_loss": 0.00027125907712616026
    },
    {
      "epoch": 950,
      "train_loss": 0.0003436267813958693
    },
    {
      "epoch": 960,
      "train_loss": 0.00032121914555318656
    },
    {
      "epoch": 970,
      "train_loss": 0.00027123668158310463
    },
    {
      "epoch": 980,
      "train_loss": 0.00029308546290849333
    },
    {
      "epoch": 990,
      "train_loss": 0.00027368441049475223
    }
  ]
}